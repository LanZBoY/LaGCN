{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '.\\\\dataset\\\\SLTC\\\\'\n",
    "TARGET = '.\\\\ProcessedData\\\\'\n",
    "dirs = os.listdir(ROOT)\n",
    "dataset_names = {\n",
    "    \"20NewsGroup\": \"20NG\",\n",
    "    \"IMDB\":\"IMDB\",\n",
    "    \"MovieReview\":\"mr\",\n",
    "    \"Ohsumed\":\"ohsumed_single_23\",\n",
    "    \"R52\":\"R52\",\n",
    "    \"R8\":\"R8\"\n",
    "}\n",
    "TRAIN_FILE_NAME = 'train_data.csv'\n",
    "TEST_FILE_NAME = 'test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get20NG(ROOT, dir):\n",
    "    data_path = os.path.join(ROOT, dir)\n",
    "    train_data = pd.read_csv(os.path.join(data_path, '20NG_train.csv'), index_col=False)\n",
    "    test_data = pd.read_csv(os.path.join(data_path, '20NG_test.csv'), index_col=False)\n",
    "    return train_data, test_data\n",
    "def getIMDB(ROOT, dir):\n",
    "    pass\n",
    "def getMR(ROOT, dir):\n",
    "    data_path = os.path.join(ROOT, dir)\n",
    "    with open(os.path.join(data_path, 'text_train.txt'), encoding='utf-8') as f:\n",
    "        train_text = [text.replace('\\n', '') for text in f.readlines()]\n",
    "    with open(os.path.join(data_path, 'label_train.txt'), encoding='utf-8') as f:\n",
    "        train_label = [int(label) for label in f.readlines()]\n",
    "    train_data = {'target': train_label, 'text': train_text}\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "\n",
    "    with open(os.path.join(data_path, 'text_test.txt'), encoding='utf-8') as f:\n",
    "        test_text = [text.replace('\\n', '') for text in f.readlines()]\n",
    "    with open(os.path.join(data_path, 'label_test.txt'), encoding='utf-8') as f:\n",
    "        test_label = [int(label) for label in f.readlines()]\n",
    "    test_data = {'target': test_label, 'text': test_text}\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    return train_data, test_data\n",
    "def getOhsumed(ROOT, dir):\n",
    "    data_path = os.path.join(ROOT, dir)\n",
    "    label2idx = {label: i for i, label in enumerate(os.listdir(os.path.join(data_path, 'train')))}\n",
    "    train_data = {'target' : [], 'text' : []}\n",
    "    for key in label2idx.keys():\n",
    "        train_path = os.path.join(os.path.join(data_path, 'train'), key)\n",
    "        for filename in os.listdir(train_path):\n",
    "            filepath = os.path.join(train_path, filename)\n",
    "            with open(filepath, 'r' ,encoding='utf-8') as f:\n",
    "                train_data['target'].append(label2idx[key])\n",
    "                train_data['text'].append(f.read())\n",
    "    test_data = {'target' : [], 'text' : []}\n",
    "    for key in label2idx.keys():\n",
    "        test_path = os.path.join(os.path.join(data_path, 'test'), key)\n",
    "        for filename in os.listdir(test_path):\n",
    "            filepath = os.path.join(test_path, filename)\n",
    "            with open(filepath, 'r' ,encoding='utf-8') as f:\n",
    "                test_data['target'].append(label2idx[key])\n",
    "                test_data['text'].append(f.read())\n",
    "    train_data = pd.DataFrame(train_data)\n",
    "    test_data = pd.DataFrame(test_data)\n",
    "    return train_data, test_data\n",
    "def getReuters(ROOT, dir):\n",
    "    data_path = os.path.join(ROOT, dir)\n",
    "    train_data = pd.read_csv(os.path.join(data_path, 'train.txt'), sep='\\t', index_col=False)\n",
    "    test_data = pd.read_csv(os.path.join(data_path, 'test.txt'), sep='\\t', index_col=False)\n",
    "    train_data.rename(columns={'Label':'target', \"Text\":'text'}, inplace=True)\n",
    "    test_data.rename(columns={'Label':'target', \"Text\":'text'}, inplace=True)\n",
    "    label2idx = {label : i for i, label in enumerate(train_data['target'].unique())}\n",
    "    train_data['target'] = train_data['target'].map(lambda x : label2idx[x])\n",
    "    test_data['target'] = test_data['target'].map(lambda x : label2idx[x])\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in dirs:\n",
    "    # print(f'Current dataset : {dir}')\n",
    "    target = os.path.join(TARGET, dir)\n",
    "    if (not os.path.isdir(target)):\n",
    "        os.mkdir(target)\n",
    "    \n",
    "    if (dataset_names['20NewsGroup'] == dir):\n",
    "        train_data, test_data = get20NG(ROOT, dir)\n",
    "    elif (dataset_names['IMDB'] == dir):\n",
    "        pass\n",
    "    elif (dataset_names['MovieReview'] == dir):\n",
    "        train_data, test_data = getMR(ROOT, dir)\n",
    "    elif (dataset_names['Ohsumed'] == dir):\n",
    "        train_data, test_data = getOhsumed(ROOT, dir)\n",
    "    elif (dataset_names['R52'] == dir):\n",
    "        train_data, test_data = getReuters(ROOT, dir)\n",
    "    elif (dataset_names['R8'] == dir):\n",
    "        train_data, test_data = getReuters(ROOT, dir)\n",
    "    else:\n",
    "        print(\"Uknown dataset\")\n",
    "        break\n",
    "\n",
    "    if (train_data is not None and test_data is not None):\n",
    "        train_data.to_csv(os.path.join(target, TRAIN_FILE_NAME), index=False)\n",
    "        test_data.to_csv(os.path.join(target, TEST_FILE_NAME), index=False)\n",
    "        train_data = None\n",
    "        test_data = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df88e35f54e019d6b6fa139624247b3dae6722fb16ba3fe7ba3d2dac403195d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
