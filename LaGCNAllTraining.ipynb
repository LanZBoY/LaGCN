{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wen2Tee5\\Desktop\\Postgraduate\\final\\finalEnv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from model import Vocaburary, TextGCN\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 300\n",
    "HIDDEN_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = {\n",
    "    \"20NewsGroup\": \"20NG\",\n",
    "    \"MR\":\"mr\",\n",
    "    \"Ohsumed\":\"ohsumed_single_23\",\n",
    "    \"R52\":\"R52\",\n",
    "    \"R8\":\"R8\"\n",
    "}\n",
    "\n",
    "result = {k : {} for k in dataset_names.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = './result/all_traning.result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAVE_PATH):\n",
    "    for key in dataset_names.keys():\n",
    "        print(\"===================================\")\n",
    "        print(key)\n",
    "        dir_name = dataset_names[key]\n",
    "        # init to memory\n",
    "        start_time = time()\n",
    "        dict_data = torch.load(f'./ProcessedData/{dir_name}/WholeGraphDict.gh')\n",
    "        voc : Vocaburary = dict_data['voc']\n",
    "        whole_graph = dict_data['whole_graph'].cuda()\n",
    "        word_num = dict_data['W']\n",
    "        label_num = dict_data['L']\n",
    "        doc_num = dict_data['D']\n",
    "        train_mask = dict_data['train_mask'].cuda()\n",
    "        doc_Y : torch.Tensor = dict_data['doc_Y'].cuda()\n",
    "        word_Y : torch.Tensor = dict_data['word_Y'].T.cuda()\n",
    "        label_Y : torch.Tensor = dict_data['label_Y'].cuda()\n",
    "        train_words = list(dict_data['train_word'])\n",
    "        test_words = list(dict_data['test_word'])\n",
    "        train_words.sort()\n",
    "        test_words.sort()\n",
    "        train_num = train_mask.count_nonzero().cpu().item()\n",
    "        test_num = doc_num - train_num\n",
    "\n",
    "        result[key]['statistic'] = {\n",
    "        \"#DOC\":doc_num,\n",
    "        \"#Word\":word_num,\n",
    "        \"#Class\":label_num,\n",
    "        \"#Train\" : train_num,\n",
    "        \"#Test\" : test_num,\n",
    "        \"#NODE\" : word_num + doc_num + label_num\n",
    "        }\n",
    "        result[key]['init_time'] = time() - start_time\n",
    "        # end of init\n",
    "\n",
    "        model = TextGCN(whole_graph.shape[0], HIDDEN_DIM, label_num).cuda()\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        trainingProcess = tqdm(range(EPOCH))\n",
    "        result[key]['testing_time_per_epoch'] = []\n",
    "        result[key]['training_time_per_epoch'] = []\n",
    "        result[key]['loss'] = []\n",
    "        result[key]['test_accuracy'] = []\n",
    "        for epoch in trainingProcess:\n",
    "            # start of training\n",
    "            training_start_time_per_epoch = time()\n",
    "            total_loss = 0.\n",
    "            optim.zero_grad()\n",
    "            y_hat = model(whole_graph)\n",
    "            doc_Y_hat = y_hat[:doc_num]\n",
    "            word_Y_hat = y_hat[doc_num:-label_num]\n",
    "            label_Y_hat = y_hat[doc_num+word_num :]\n",
    "            doc_loss = loss_fn(doc_Y_hat[train_mask], doc_Y[train_mask])\n",
    "            word_loss = loss_fn(word_Y_hat[train_words], word_Y[train_words])\n",
    "            label_loss = loss_fn(label_Y_hat, label_Y)\n",
    "            loss = 1.0 * doc_loss + 1.0 * word_loss  + 1.0 * label_loss\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            result[key]['training_time_per_epoch'].append(time() - training_start_time_per_epoch)\n",
    "            # end of training_per_epoch\n",
    "            loss_val = loss.item()\n",
    "            # start of testing_per_epoch\n",
    "            testing_start_time_per_epoch = time()\n",
    "            with torch.no_grad():\n",
    "                acc_val = ((doc_Y_hat.argmax(1)[~train_mask] == doc_Y.cuda()[~train_mask]).sum() / (~train_mask).sum()).item()\n",
    "            result[key]['testing_time_per_epoch'].append(time() - testing_start_time_per_epoch)\n",
    "            # end of testing_per_epoch\n",
    "            result[key]['loss'].append(loss_val)\n",
    "            result[key]['test_accuracy'].append(acc_val)\n",
    "            trainingProcess.set_postfix({\"LOSS\": loss_val, \"ACC\" : acc_val})\n",
    "    with open(SAVE_PATH, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "else:\n",
    "    with open(SAVE_PATH, 'rb') as f:\n",
    "        result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Result of 20NewsGroup\n",
      "{'#DOC': 18846, '#Word': 42757, '#Class': 20, '#Train': 11314, '#Test': 7532, '#NODE': 61623}\n",
      "Init Time = 0.7369239330291748\n",
      "Total Training Time = 96.07711815834045\n",
      "Total Testing Time = 0.12513041496276855\n",
      "Excution Time = 96.9391725063324\n",
      "BEST_EPOCH Accuracy = 0.9492830634117126\n",
      "===================\n",
      "Result of MR\n",
      "{'#DOC': 10662, '#Word': 18764, '#Class': 2, '#Train': 7108, '#Test': 3554, '#NODE': 29428}\n",
      "Init Time = 0.03851199150085449\n",
      "Total Training Time = 7.527169227600098\n",
      "Total Testing Time = 0.1331028938293457\n",
      "Excution Time = 7.698784112930298\n",
      "BEST_EPOCH Accuracy = 0.9079909920692444\n",
      "===================\n",
      "Result of Ohsumed\n",
      "{'#DOC': 7400, '#Word': 14157, '#Class': 23, '#Train': 3357, '#Test': 4043, '#NODE': 21580}\n",
      "Init Time = 0.08857846260070801\n",
      "Total Training Time = 28.773300886154175\n",
      "Total Testing Time = 0.14446735382080078\n",
      "Excution Time = 29.006346702575684\n",
      "BEST_EPOCH Accuracy = 0.8864704370498657\n",
      "===================\n",
      "Result of R52\n",
      "{'#DOC': 9100, '#Word': 8892, '#Class': 52, '#Train': 6532, '#Test': 2568, '#NODE': 18044}\n",
      "Init Time = 0.048859357833862305\n",
      "Total Training Time = 16.7758207321167\n",
      "Total Testing Time = 0.12313103675842285\n",
      "Excution Time = 16.947811126708984\n",
      "BEST_EPOCH Accuracy = 0.9575545191764832\n",
      "===================\n",
      "Result of R8\n",
      "{'#DOC': 7674, '#Word': 7688, '#Class': 8, '#Train': 5485, '#Test': 2189, '#NODE': 15370}\n",
      "Init Time = 0.036028385162353516\n",
      "Total Training Time = 12.702450513839722\n",
      "Total Testing Time = 0.13060235977172852\n",
      "Excution Time = 12.869081258773804\n",
      "BEST_EPOCH Accuracy = 0.9890360832214355\n"
     ]
    }
   ],
   "source": [
    "for key in result.keys():\n",
    "    print(f\"===================\")\n",
    "    print(f\"Result of {key}\")\n",
    "    # statistic\n",
    "    print(result[key]['statistic'])\n",
    "    print(f\"Init Time = {result[key]['init_time']}\")\n",
    "    print(f\"Total Training Time = {sum(result[key]['training_time_per_epoch'])}\")\n",
    "    print(f\"Total Testing Time = {sum(result[key]['testing_time_per_epoch'])}\")\n",
    "    print(f\"Excution Time = {sum(result[key]['training_time_per_epoch']) + sum(result[key]['testing_time_per_epoch']) + result[key]['init_time']}\")\n",
    "\n",
    "    print(f\"BEST_EPOCH Accuracy = {max(result[key]['test_accuracy'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
